## 小米

### 自我介绍

### 项目深挖

------

### Java内存模型

`JMM(Java 内存模型)`主要定义了对于一个**共享变量**，当另一个线程对这个共享变量执行写操作后，这个线程对这个共享变量的可见性。

**CPU Cache 缓存的是内存数据用于解决 CPU 处理速度和内存不匹配的问题，内存缓存的是硬盘数据用于解决硬盘访问速度过慢的问题。**

**Java 内存模型（JMM）** 抽象了线程和主内存之间的关系，就比如说线程之间的共享变量必须存储在主内存中。

Java内存模型（Java Memory Model，JMM）是Java虚拟机规范中定义的一种抽象概念，用于描述`Java程序中多线程并发访问共享内存时的行为规则和内存可见性规范`。JMM定义了线程之间如何进行内存交互，以及在何种条件下对共享变量的读取、写入操作会在多线程环境中产生哪些影响。

Java内存模型主要包含以下几个方面：

1. **主内存（Main Memory）**：
   - 主内存是所有线程共享的内存区域，包含了所有的共享变量。
   - 所有的变量都存储在主内存中，而不是线程的本地内存中。
2. **工作内存（Working Memory）**：
   - 每个线程都有自己的工作内存，用于存储线程私有的变量和对共享变量的副本。
   - 线程对变量的所有操作都必须在工作内存中进行，不能直接读写主内存中的变量。
3. **内存交互操作**：
   - 内存交互操作指的是线程之间进行数据交互的操作，包括对共享变量的读写操作。
   - 内存交互操作必须满足一定的顺序性和原子性规则，以保证多线程环境下的内存可见性和一致性。
4. **内存可见性**：
   - 内存可见性指的是当一个线程对共享变量的修改对其他线程是可见的。
   - Java内存模型通过“**happens-before**”关系来确保内存可见性，即在一个线程的操作前发生的操作对于后续的操作是可见的。
5. **顺序性一致性**：
   - 顺序性一致性指的是程序执行的结果必须与其顺序执行的结果相同，即程序的执行顺序不能被重排序。
   - Java内存模型通过“happens-before”关系和内存屏障等机制来确保程序的顺序性一致性。

Java内存模型的设计旨在提供一种简单而有效的机制，以确保在多线程环境下程序的正确性和可靠性。开发者可以依靠Java内存模型的规范来编写正确的并发程序，并通过锁、volatile关键字、synchronized关键字等机制来保证程序的正确性和性能。

**happens-before 原则的设计思想：**

- 为了对编译器和处理器的约束尽可能少，只要不改变程序的执行结果（单线程程序和正确执行的多线程程序），编译器和处理器怎么进行重排序优化都行。
- 对于会改变程序执行结果的重排序，JMM 要求编译器和处理器必须禁止这种重排序。

------

### **原子性，可见性，有序性**

**原子性**：一次操作或者多次操作，要么所有的操作全部都得到执行并且不会受到任何因素的干扰而中断，要么都不执行。

- 在 Java 中，可以借助`synchronized`、各种 `Lock` 以及各种原子类实现原子性。
- `synchronized` 和各种 `Lock` 可以保证任一时刻只有一个线程访问该代码块，因此可以保障原子性。
- 各种原子类是利用 CAS (compare and swap) 操作（可能也会用到 `volatile`或者`final`关键字）来保证原子操作。

**可见性**: 当一个线程对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。

- 在 Java 中，可以借助`synchronized`、`volatile` 以及各种 `Lock` 实现可见性。

- 如果我们将变量声明为 `volatile` ，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。

**有序性**: 由于指令重排序问题，代码的执行顺序未必就是编写代码时候的顺序。

- **指令重排序可以保证串行语义一致，但是没有义务保证多线程间的语义也一致** ，所以在多线程下，指令重排序可能会导致一些问题。
- 在 Java 中，`volatile` 关键字可以禁止指令进行重排序优化。

------

### **volatile关键字**

`volatile` 关键字在 Java 中用于修饰变量，它具有两个主要的作用：

1. **可见性（Visibility）**：
   - 当一个变量被 `volatile` 关键字修饰时，线程在读取该变量的值时会直接从主内存中读取，而不是从线程的本地内存中读取。同时，当一个线程修改了 `volatile` 变量的值后，会立即将修改后的值刷新到主内存中，以保证其他线程能够立即看到这个变化。
   - 因此，`volatile` 可以保证多个线程对变量的修改是可见的，避免了线程之间的数据不一致性问题。
2. **禁止指令重排序（Prevent Instruction Reordering）**：
   - `volatile` 关键字可以防止编译器对被修饰变量相关的代码进行重排序优化，以确保对变量的修改指令不会被重排序到其后面的代码之前。
   - 这样可以避免出现多线程环境下的执行顺序不确定性导致的问题，确保程序的正确性。

总之，`volatile` 关键字主要用于修饰多线程共享的变量，确保其在多线程环境中的可见性和一致性。需要注意的是，`volatile` 关键字只能保证变量读取和赋值的原子性，并不能保证复合操作的原子性。因此，在某些情况下还需要结合其他并发控制手段（如锁）来确保线程安全。

### Java 实现同步机制的方法，加锁方式

Java 实现同步机制的方法主要包括以下几种，其中加锁方式是最常见和最基础的一种：

**synchronized 关键字**：使用 `synchronized` 关键字可以在方法级别或代码块级别对代码进行加锁。当一个线程获得了对象的锁后，其他试图访问该对象同步代码块的线程将被阻塞，直到持有锁的线程释放锁。

```java
codepublic synchronized void synchronizedMethod() {
    // 同步方法体
}

synchronized (obj) {
    // 同步代码块
}
```

**ReentrantLock 类**：`ReentrantLock` 是 Java.util.concurrent 包中提供的锁对象，提供了与 `synchronized` 关键字类似的功能，但更加灵活。它支持手动加锁和解锁、可中断的锁等高级特性。

```java
codeReentrantLock lock = new ReentrantLock();
lock.lock(); // 获取锁
try {
    // 临界区代码
} finally {
    lock.unlock(); // 释放锁
}
```

**读写锁（ReadWriteLock 接口）**：`ReadWriteLock` 接口定义了读锁和写锁，读锁可以被多个线程同时持有，写锁只能被一个线程持有。适用于对共享资源进行频繁读操作的场景。

```java
codeReadWriteLock lock = new ReentrantReadWriteLock();
lock.readLock().lock(); // 获取读锁
try {
    // 读操作
} finally {
    lock.readLock().unlock(); // 释放读锁
}
```

**使用 synchronized 和 wait/notify/notifyAll 实现等待通知机制**：`wait()` 方法用于使当前线程进入等待状态，并释放对象的锁；`notify()` 和 `notifyAll()` 方法用于唤醒等待队列中的线程。

```java
codesynchronized (obj) {
    while (condition) {
        obj.wait(); // 等待
    }
    // 执行业务逻辑
    obj.notify(); // 唤醒等待线程
}
```

### 线程池的创建和管理

线程池是一种用于管理和复用线程的机制，可以有效地控制并发执行的线程数量，提高系统的性能和资源利用率。在Java中，可以使用 `java.util.concurrent` 包提供的 `ThreadPoolExecutor` 类来创建和管理线程池。

线程池的好处：

- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**。当任务到达时，任务可以不需要等到线程创建就能立即执行。
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

下面是线程池的创建和管理步骤：

1. **创建线程池**：可以通过 `ThreadPoolExecutor` 的构造方法来创建线程池。常用的构造方法包括：

   ```java
   ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue)
   ```

   这个构造方法需要传入以下参数：

   - `corePoolSize`：核心线程数，线程池中保持存活的最少线程数。
   - `maximumPoolSize`：最大线程数，线程池中允许的最大线程数。
   - `keepAliveTime`：空闲线程的存活时间，当线程池中的线程数量超过核心线程数时，多余的空闲线程在这个时间段内没有任务可执行时会被销毁。
   - `unit`：时间单位，通常使用 `TimeUnit.SECONDS` 或 `TimeUnit.MILLISECONDS`。
   - `workQueue`：工作队列，用于存放待执行的任务。
   - `threadFactory` :executor 创建新线程的时候会用到。
   - `handler`: 饱和策略。

2. **提交任务**：创建了线程池之后，可以使用 `execute()` 方法提交任务给线程池执行。也可以使用 `submit()` 方法提交带有返回值的任务。

   ```java
   ThreadPoolExecutor executor = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue);
   executor.execute(new RunnableTask());
   ```

3. **关闭线程池**：当不再需要线程池时，应该调用 `shutdown()` 方法关闭线程池。这会使线程池不再接受新任务，并尝试将已经提交但未执行的任务执行完毕后关闭。

   ```java
   executor.shutdown();
   ```

4. **优雅关闭线程池**：在调用 `shutdown()` 方法后，可以使用 `awaitTermination()` 方法等待线程池中的任务执行完毕，或者设置 `awaitTermination()` 方法的超时时间来确保线程池在指定时间内关闭完成。

   ```java
   codeif (!executor.awaitTermination(60, TimeUnit.SECONDS)) {
       executor.shutdownNow(); // 如果超时则强制关闭线程池
   }
   ```

通过合理设置线程池的参数，可以有效地管理并发执行的任务，避免因线程的频繁创建和销毁而带来的性能开销，提高系统的稳定性和性能。

### 当用户量特别大的时候，如何设计用户表？

1. **数据分片**：对用户表进行数据分片是必要的，以分担数据库的读写压力。可以根据用户ID的哈希值或者按照一定的规则将用户数据分散存储在不同的物理节点上，实现水平扩展。
2. **垂直分割**：将用户表按照业务逻辑进行垂直分割，将常用和不常用的字段分开存储。例如，将用户基本信息、安全信息、关联信息等分开存储，以减少单个表的宽度。
3. **冗余字段**：可以在用户表中添加一些冗余字段，以减少数据库查询的次数。例如，在用户表中添加一些常用的统计信息或者缓存一些需要频繁读取的数据。
4. **索引优化**：根据业务需求和查询频率创建合适的索引，以提高查询效率。但需要注意索引的数量和类型不宜过多，以避免影响写入性能和增加存储成本。
5. **缓存**：使用缓存技术（如Redis）缓存用户数据，减少数据库的读取压力。可以将热门用户数据缓存到内存中，提高读取速度。
6. **异步处理**：对于一些不需要实时处理的操作，可以使用消息队列或者异步任务进行处理，减少对数据库的直接访问。
7. **数据压缩**：对于一些文本字段或者大字段，可以考虑进行数据压缩存储，以节省存储空间和提高读取速度。
8. **水平扩展**：采用分布式数据库架构，通过增加数据库节点来实现水平扩展，以应对用户量的增长。

### 索引有哪些，索引失效有哪些情况？

MySQL 中常见的索引类型包括以下几种：

1. **普通索引（Normal Index）**：最基本的索引类型，没有任何限制。
2. **唯一索引（Unique Index）**：保证索引列的唯一性，用于加速唯一性约束的检查和查询。
3. **主键索引（Primary Key Index）**：主键索引是一种特殊的唯一索引，用于唯一标识每一行数据。每个表只能有一个主键索引。
4. **组合索引（Composite Index）**：针对多个列创建的组合索引，可以加速多列组合查询的效率。复合索引的列顺序很重要，通常应该将最常用于过滤条件的列放在前面。
5. **全文索引（Full-Text Index）**：针对文本字段创建的索引，用于支持全文搜索功能，例如使用 `FULLTEXT` 索引类型。
6. **空间索引（Spatial Index）**：用于支持空间数据类型（如点、线、多边形）的查询，例如使用 `SPATIAL` 索引类型。

MySQL 索引失效的情况主要包括以下几种：

1. **索引列未在查询条件中使用**：如果查询条件中没有使用到索引列，那么索引就无法起到加速查询的作用，数据库会选择进行全表扫描。
2. **对索引列进行了函数操作**：如果在查询条件中对索引列进行了函数操作，例如 `WHERE DATE_FORMAT(create_time, '%Y-%m-%d') = '2022-01-01'`，那么索引就无法被利用，数据库会选择进行全表扫描。
3. **索引列使用了不等于操作符（<>, !=）**：如果查询条件中使用了不等于操作符，例如 `WHERE status <> 0`，通常情况下索引也无法被利用。
4. **使用了 OR 条件**：如果查询条件中使用了 OR 条件，但是 OR 条件中的每个条件都没有涉及到索引列，那么索引也无法被利用。
5. **范围查询**：对于范围查询（例如 BETWEEN、<、>）或者使用了排序操作的查询，如果索引列不是范围的最左前缀，那么索引可能无法被利用。
6. **表数据量过小**：当表数据量很小的时候，使用索引可能不如全表扫描高效，数据库会选择放弃索引而直接进行全表扫描。

### 如何排查数据库查询速度比较慢的问题？

1. **确定慢查询**：首先需要确定哪些查询速度比较慢。可以通过数据库的慢查询日志或者性能监控工具来查看执行时间较长的查询语句。
2. **分析执行计划**：针对慢查询，可以通过数据库提供的工具分析其执行计划。执行计划可以告诉你数据库是如何执行查询的，以及是否使用了索引等优化手段。
3. **检查索引**：确保查询语句中涉及的列上有合适的索引。可以通过 `EXPLAIN` 命令来查看查询语句的执行计划，并确认是否使用了索引。
4. **检查数据量**：查询的数据量是否过大，导致查询速度变慢。可以通过 `LIMIT` 关键字限制查询结果的数量，或者通过分页等方式减少查询数据量。
5. **检查索引覆盖**：检查查询是否可以使用索引覆盖，即只通过索引就能够完成查询，而不需要回表查询数据。这样可以减少磁盘IO和内存使用，提高查询速度。
6. **检查锁和阻塞**：检查是否有其他查询或事务导致了锁和阻塞，影响了当前查询的执行速度。可以通过数据库的锁信息和等待信息来排查。
7. **检查数据库配置**：检查数据库的配置参数是否合理，例如缓冲池大小、连接池大小、最大连接数等。适当调整这些参数可以提高数据库的性能。
8. **性能监控**：定期监控数据库的性能指标，如CPU利用率、内存利用率、磁盘IO等，及时发现和排查性能问题。
9. **数据库优化**：根据具体情况进行数据库优化，例如优化查询语句、调整表结构、分区等，以提高数据库的性能和稳定性。

### 返回部分字段和返回全部字段有什么区别？

返回部分字段和返回全部字段的主要区别在于返回结果集的大小和网络传输的开销：

1. **返回结果集的大小**：
   - 返回部分字段会减少结果集的大小，因为只返回指定的字段数据，而不包含所有字段的数据。这可以减少数据库的内存消耗和网络传输的数据量。
   - 返回全部字段会包含所有字段的数据，结果集的大小会更大，尤其是当表中包含大量的字段或者大字段时，返回全部字段会消耗更多的内存和网络带宽。
2. **网络传输的开销**：
   - 返回部分字段可以减少网络传输的开销，因为传输的数据量更小。这对于网络速度较慢或者网络带宽有限的环境下特别重要，可以减少网络延迟和响应时间。
   - 返回全部字段会增加网络传输的开销，因为传输的数据量更大。尤其是在分布式系统或者远程访问数据库的情况下，网络传输的开销会更加明显。
3. **数据处理的开销**：
   - 返回部分字段可以减少数据处理的开销，因为数据库引擎不需要检索和处理所有字段的数据，而只需要处理指定的字段数据。
   - 返回全部字段会增加数据处理的开销，尤其是当表中包含大量的字段或者大字段时，数据库引擎需要花费更多的时间和资源来处理数据。

总的来说，返回部分字段可以减少结果集的大小和网络传输的开销，提高查询性能和系统的响应速度。因此，在设计查询语句时，应该根据实际需求和性能考虑，尽量只返回需要的字段数据，避免返回全部字段。

### MySQL 索引的数据结构

在 MySQL 中，常见的索引数据结构主要包括以下几种：

1. **B-tree 索引**（平衡树索引）：
   - B-tree（或称为B树）是一种常见的平衡树结构，用于实现数据库索引。MySQL中的InnoDB存储引擎默认使用B-tree索引。
   - B-tree索引对于范围查询和排序查询非常高效，因为B-tree索引可以保持数据有序，并且支持快速的范围查找操作。
2. **Hash 索引**（哈希索引）：
   - Hash索引基于哈希表实现，适用于等值查找。MySQL中的Memory存储引擎支持Hash索引。
   - Hash索引对于等值查询非常高效，但不支持范围查询和排序操作。
3. **Full-Text 索引**（全文索引）：
   - Full-Text索引用于支持全文搜索功能，例如使用`MATCH AGAINST`语法进行文本搜索。
   - Full-Text索引使用特殊的数据结构（如倒排索引）来实现全文搜索功能，能够有效地处理文本数据。
4. **R-tree 索引**（R树索引）：
   - R-tree索引主要用于空间数据类型（如点、线、多边形）的查询，例如使用GIS（地理信息系统）功能进行空间查询。
   - R-tree索引能够高效地处理空间数据类型的范围查询和最近邻查询等操作。
5. **Trie 索引**（前缀树索引）：
   - Trie索引基于前缀树（Trie树）实现，适用于前缀匹配查询。
   - Trie索引能够高效地处理需要按照前缀匹配查询的场景，例如搜索引擎中的自动补全功能。

### B+ 树的优点

B+树相对于其他数据结构（如B树、平衡二叉树等）有以下几个主要优点：

1. **更适合磁盘存储**：B+树的内部节点不存储数据，只存储索引，而叶子节点存储全部数据，并且叶子节点之间通过指针连接形成链表。这种设计使得B+树的叶子节点连续存储在磁盘上，减少了磁盘I/O次数，适合磁盘存储。
2. **有利于范围查询和顺序访问**：由于叶子节点之间通过指针连接形成链表，因此范围查询和顺序访问非常高效。可以通过在B+树上进行顺序遍历来获取有序的数据。
3. **减少磁盘I/O次数**：B+树的高度相对较低，并且叶子节点连续存储，这使得在进行查找、插入和删除等操作时，磁盘I/O次数较少，提高了IO效率。
4. **有利于维护平衡**：由于B+树的平衡性质，插入和删除操作相对容易实现，且可以通过局部调整来保持树的平衡，避免了频繁的平衡调整操作。
5. **支持高效的范围查询**：B+树的叶子节点形成有序链表，因此支持高效的范围查询操作。这对于许多数据库和文件系统中常见的范围查询场景非常重要。

### 分布式下，如何获取全局的唯一ID，有哪些方式？

在分布式系统中获取全局唯一ID是一个常见的需求，通常可以通过以下几种方式来实现：

1. **UUID（Universally Unique Identifier）**：
   - UUID是一种由128位数字组成的唯一标识符，可以在不同的系统之间保持唯一性。
   - 可以使用UUID生成算法（如UUIDv1、UUIDv4等）生成全局唯一的ID。
2. **Snowflake算法**：
   - Snowflake算法是Twitter开源的一种分布式唯一ID生成算法，它生成的ID是64位的整数，包含了时间戳、机器ID和序列号等信息。
   - Snowflake算法可以在分布式系统中生成全局唯一的ID，并且有一定的顺序性。
3. **数据库自增主键**：
   - 在关系型数据库中，可以使用自增主键来生成全局唯一的ID。每个数据库实例维护一个自增序列，每次插入新记录时自动递增生成ID。
   - 但是需要注意，在分布式环境下，需要对数据库实例进行适当配置和同步，以避免出现主键冲突的问题。
4. **分布式ID生成服务**：
   - 可以搭建专门的分布式ID生成服务，通过统一的算法和生成器来生成全局唯一的ID。应用程序可以通过网络请求向ID生成服务获取唯一ID。
   - 这种方式可以实现ID的集中管理和统一分配，避免了分布式环境下的主键冲突和ID生成算法的复杂性。
5. **Zookeeper节点ID**：
   - 可以使用Zookeeper这样的分布式协调服务，利用其节点的唯一性来生成全局唯一的ID。每个节点可以使用Zookeeper的节点ID作为唯一标识符。
   - 这种方式需要依赖于Zookeeper的稳定性和可靠性，适合于已经在系统中使用Zookeeper的场景。

以上是一些常见的获取全局唯一ID的方式，在实际应用中可以根据需求和场景选择合适的方式来实现。

### 设计分布式下的唯一ID，你会考虑哪些因素？

设计分布式环境下的唯一ID需要考虑多个因素，以确保生成的ID在分布式系统中具有全局唯一性、足够的性能和可伸缩性。以下是设计分布式唯一ID时需要考虑的一些因素：

1. **唯一性**：生成的ID必须在整个分布式系统中保持唯一，不同节点生成的ID不能冲突。
2. **性能**：ID生成算法和服务需要保证高性能，能够在高并发和大规模分布式环境下快速生成唯一ID。
3. **可用性**：ID生成服务需要具备高可用性，能够保证在节点故障或网络分区情况下继续提供服务。
4. **趋势递增**：生成的ID最好具有趋势递增的特性，有助于提高数据库索引的性能和减少磁盘碎片。
5. **可配置性**：ID生成服务需要具有一定的可配置性，能够根据实际需求调整生成ID的策略和参数。
6. **分布式一致性**：ID生成算法和服务需要保证在分布式环境下的一致性，不同节点生成的ID应当满足一致性要求。
7. **容错性**：ID生成服务需要具备一定的容错性，能够处理节点故障、网络分区等异常情况。
8. **可扩展性**：ID生成服务需要具备良好的可扩展性，能够方便地进行水平扩展以应对系统的增长。
9. **安全性**：生成的ID可能会暴露在外部系统中，需要考虑ID的安全性和隐私保护。
10. **可监控性**：ID生成服务需要具备一定的监控功能，能够实时监控ID的生成情况和性能指标。

在设计分布式唯一ID时，需要综合考虑以上因素，并选择合适的算法和技术来实现。通常可以采用Snowflake算法、数据库自增主键、分布式ID生成服务等方式来生成分布式环境下的唯一ID。

### 如何保证各个节点返回唯一值？

在分布式系统中保证各个节点返回唯一值是一个关键的问题。以下是一些常见的方法和策略：

1. **中心化分配唯一ID**：
   - 可以引入一个中心化的ID分配服务，由该服务负责生成唯一ID，并分配给各个节点。
   - 当节点需要生成唯一ID时，向中心化服务请求ID，中心化服务保证生成的ID在系统中唯一。
2. **基于数据库自增主键**：
   - 可以使用数据库的自增主键功能，在数据库中维护一个全局唯一的ID序列。
   - 每个节点在需要生成唯一ID时，向数据库请求自增主键，数据库保证分配的ID在系统中唯一。
3. **基于Snowflake算法**：
   - Snowflake算法是一种分布式唯一ID生成算法，它结合了时间戳、节点ID和序列号等信息来生成唯一ID。
   - 每个节点在初始化时分配一个唯一的节点ID，并按照Snowflake算法生成唯一ID。
4. **基于Zookeeper节点ID**：
   - 可以利用Zookeeper这样的分布式协调服务，利用其节点的唯一性来生成唯一ID。
   - 每个节点在启动时注册到Zookeeper集群，并获取唯一的节点ID作为标识符。
5. **一致性哈希算法**：
   - 可以使用一致性哈希算法将ID分布到不同的节点上，每个节点负责生成一定范围内的唯一ID。
   - 通过哈希算法，保证同一ID范围的请求都路由到相同的节点，从而保证生成的ID在系统中唯一。
6. **分布式锁**：
   - 可以使用分布式锁机制来保证只有一个节点可以生成唯一ID，其他节点需要等待锁释放后才能生成ID。
   - 这种方式可能会引入较高的延迟和复杂性，不适合高并发场景。

### Redis 如何清除过期数据

Redis清除过期数据是通过**定期执行过期键的淘汰策略**来实现的。具体而言，Redis使用了一种称为定期删除（Eviction）的策略，通过定期检查键的过期时间，并在键过期后立即删除它们。

下面是Redis清除过期数据的主要步骤：

1. **定期检查**：Redis会以一定的频率（由`hz`配置参数决定，默认为10）检查部分键的过期时间是否已经到达。
2. **过期键检测**：对于已经过期的键，Redis会在读取或写入该键时检测到过期，并在此时将其删除。
3. **惰性删除**：如果键过期后未被访问，Redis会在访问该键时立即删除它。这种方式称为惰性删除（Lazy deletion）。
4. **定期删除**：Redis还会启动一个后台任务，定期扫描一定数量的键并删除过期的键。该任务执行的频率由`hz`参数决定。
5. **内存策略**：Redis的内存策略也影响着过期数据的清除。当内存使用达到最大内存限制时，Redis会根据所配置的内存淘汰策略（如LRU、LFU等）来决定删除哪些键。

总的来说，Redis清除过期数据是通过定期检查键的过期时间并执行定期删除策略来实现的。这种机制保证了Redis在不产生大量阻塞的情况下，能够及时地清除过期数据，有效地管理内存空间。

### Redis 的持久化机制


Redis 的持久化机制有两种主要方式：RDB（Redis DataBase）和AOF（Append Only File）。

1. **RDB（Redis DataBase）持久化**：
   - RDB 是 Redis 的默认持久化方式，它可以`在指定的时间间隔`内`将 Redis 数据以快照的形式保存到磁盘上的一个文件中`。
   - RDB 持久化是通过 fork 子进程来完成的，它会先将数据写入临时文件，然后再用该文件替换旧的 RDB 文件，以保证持久化文件的完整性和一致性。
   - RDB 适用于数据备份和恢复，因为它生成的文件是一个完整的数据快照，可以在需要时进行快速的恢复。
2. **AOF（Append Only File）持久化**：
   - AOF 持久化是通过`记录 Redis 服务器接收到的每个写操作来保持数据库的持久化`，写操作以追加的方式记录到一个日志文件中。
   - AOF 文件中记录的是写命令本身，而不是整个数据集的快照，因此 AOF 文件通常比 RDB 文件大。
   - AOF 持久化可以保证更高的数据安全性，因为每个写操作都会被记录下来，可以确保不会丢失任何数据。
   - AOF 文件通常会比 RDB 文件更加消耗磁盘空间和写入性能，但它提供了更好的数据持久化保证。

除了以上两种持久化方式，Redis 还支持两种持久化方式的混合使用。可以通过配置文件中的相关参数来选择使用哪种持久化方式，以及如何进行持久化数据的保存和加载。

### RDB 和 AOF 方式的区别


`RDB（Redis DataBase）`和`AOF（Append Only File）`是`Redis`中两种不同的持久化方式，它们有以下主要区别：

1. **持久化原理**：
   - **RDB持久化**：RDB持久化是通过在指定的时间间隔内将Redis的数据以快照的形式保存到磁盘上的一个文件中。这个文件是一个二进制文件，包含了数据库在某个时间点上的所有键值对数据。
   - **AOF持久化**：AOF持久化是通过记录Redis服务器接收到的每个写操作来保持数据库的持久化，`写操作以追加的方式`记录到一个日志文件中。AOF文件中记录的是写命令本身，而不是整个数据集的快照。
2. **数据完整性**：
   - **RDB持久化**：RDB生成的文件是一个完整的数据快照，包含了数据库在某个时间点上的所有数据，因此恢复数据时速度比较快。
   - **AOF持久化**：AOF文件中记录了每个写操作，因此可以保证更高的数据安全性，但是恢复数据时速度可能会比较慢，特别是当AOF文件比较大时。
3. **文件大小**：
   - **RDB持久化**：RDB文件通常比较小，因为它只包含了一个时间点上的数据快照。
   - **AOF持久化**：AOF文件通常比较大，因为它记录了每个写操作，且文件大小会随着写操作的增加而增加。
4. **数据丢失**：
   - **RDB持久化**：在RDB持久化方式下，如果Redis服务器突然宕机，可能会丢失最后一次生成RDB文件之后的数据。
   - **AOF持久化**：在AOF持久化方式下，即使Redis服务器突然宕机，也可以通过AOF文件来恢复数据，只会丢失最后一次写操作之后的数据。
5. **写入性能**：
   - **RDB持久化**：生成RDB文件时，Redis会创建一个子进程来执行数据的持久化操作，会对性能产生一定影响。
   - **AOF持久化**：由于AOF文件需要记录每个写操作，因此写入性能可能会受到一定影响，特别是当AOF文件比较大时。

综上所述，RDB持久化适用于数据备份和恢复，速度快但可能会丢失一部分数据；AOF持久化适用于保证数据的安全性，但文件比较大，且恢复速度可能较慢。在实际应用中，可以根据需求和场景选择合适的持久化方式，或者同时使用两种持久化方式以提高数据安全性和恢复速度。

### Redis 缓存异常的三个问题以及如何解决

在使用Redis作为缓存时，常见的三个异常问题包括：

1. **缓存穿透**：
   - **问题描述**：缓存穿透指的是客户端请求的数据在缓存中和数据库中都不存在，这样缓存永远不会生效，这些请求都会打到数据库
   - 解决方案：
     - 使用**布隆过滤器（Bloom Filter）**来快速过滤掉不存在于缓存中的请求。
     - 对于查询为空的请求，也将其缓存起来，并设置一个较短的过期时间，避免反复查询。
2. **缓存击穿**：
   - **问题描述**：缓存击穿指的是某个热点数据突然过期或者被删除，导致大量请求同时访问数据库，给数据库造成压力。
   - 解决方案：
     - 使用**互斥锁（Mutex Lock）或者分布式锁，**在访问数据库之前进行加锁操作，只允许一个请求访问数据库，其他请求等待。
     - 针对热点数据，可以设置永不过期或者较长的过期时间，以减少缓存失效的可能性。
3. **缓存雪崩**：
   - **问题描述**：缓存雪崩指的是大量缓存同时失效，导致大量请求直接访问数据库，给数据库造成压力。
   - 解决方案：
     - 设置缓存的过期时间随机偏移，避免大量缓存同时过期。
     - 使用主从复制或者集群模式，提高Redis的可用性和容错性，减少单点故障的可能性。
     - 引入熔断机制或者限流机制，限制请求访问数据库的并发数，避免数据库被过多请求压垮。

通过以上解决方案，可以有效地应对Redis缓存异常问题，提高系统的稳定性和性能。

### 布隆过滤器存在什么问题

布隆过滤器（Bloom Filter）是一种空间效率高、插入和查询时间复杂度低的数据结构，`用于判断一个元素是否可能存在于一个集合中。`

布隆过滤器基于一个**位数组（Bit Array）和多个哈希函数**构成。它的基本原理是将每个元素经过多个哈希函数映射成位数组中的多个位置，将这些位置置为1。当查询一个元素时，布隆过滤器会对该元素经过相同的哈希函数映射得到的位置进行查询，只有当所有位置都为1时，才认为元素可能存在于集合中；如果有任何一个位置为0，则可以肯定元素不存在于集合中。

由于布隆过滤器的查询操作只需要对位数组进行查询，**时间复杂度为O(k)**，其中k是哈希函数的数量。因此，布隆过滤器的查询速度非常快。同时，布隆过滤器的空间消耗相对较小，因为它只需要一个位数组来存储数据的存在情况，不需要存储元素本身。

布隆过滤器主要用于解决以下两个问题：

1. **判定一个元素是否可能存在于一个集合中**：例如在网络爬虫中，用于判定一个URL是否已经被访问过，避免重复访问。
2. **去重过滤**：例如在分布式系统中，用于判定某个请求是否已经处理过，避免重复处理。

需要注意的是，布隆过滤器存在一定的误判率，即有可能判定一个元素存在于集合中，但实际上并不存在。误判率取决于位数组的大小和哈希函数的数量，可以通过调整参数来平衡误判率和空间消耗。

布隆过滤器虽然在某些场景下可以帮助解决一些问题，但也存在一些问题和限制：

1. **误判率（False Positive）**：
   - 布隆过滤器是基于哈希函数实现的，因此存在一定的误判率。即使元素不在集合中，布隆过滤器也可能会认为元素存在，这就是误判。
   - 误判率受到布隆过滤器的大小和哈希函数数量等参数的影响。误判率越低，布隆过滤器的空间消耗和哈希计算的时间开销就越大。
2. **无法删除元素**：
   - 布隆过滤器中的元素一旦被添加，就无法删除。因为删除元素可能会影响到其他元素的判断结果，导致误判率增加。
   - 如果需要删除元素，只能通过重新构建布隆过滤器来实现，这会消耗一定的时间和资源。
3. **无法得知具体哪些元素被过滤**：
   - 布隆过滤器只能告诉你元素可能存在或者一定不存在，但无法告诉你具体哪些元素被过滤掉了。
   - 这意味着当布隆过滤器判断某个元素存在时，你仍然需要进一步确认是否真的存在，这可能会增加额外的查询开销。
4. **空间消耗**：
   - 布隆过滤器需要消耗一定的内存空间来存储哈希值和位图。误判率越低，需要的内存空间就越大，可能会占用较多的内存资源。
5. **不适合动态数据集**：
   - 布隆过滤器适用于静态数据集或者数据集变化不频繁的场景。如果数据集频繁变化，可能需要频繁地重新构建布隆过滤器，这会带来一定的性能开销。

综上所述，布隆过滤器虽然在某些场景下可以提供高效的去重和判定功能，但也存在一些问题和限制，需要根据具体情况进行权衡和选择。

### 反问

# 招银网络

自我介绍

项目深问

项目怎么部署上限？本地开发和上线有什么不同？

文件传输XML和JSON，为什么用XML？

Spring AOP 的用法和缺点，如何基于AOP实现操作日志，新添加一个方法，如何将其使用AOP管理起来

Spring处理异常的方式，Spring全局异常处理器

线程池的工作流程，线程池的缺点

线程池饿最大线程数量怎么设置？

TCP和UDP的区别

TCP如何实现安全可靠的传输

TCP三次握手和四次挥手

算法题：基于快速排序的思想，找到数组中第K大的数

# 小米（一面）

自我介绍

项目深问：

Java线程同步的方式

Java线程池参数、工作流程，所用到的设计模式

可重入锁